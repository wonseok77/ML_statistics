{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50aaf89-038e-4b02-9fea-c2392d6170f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF RandomForest\n",
    "# ET ExtraTree\n",
    "# GB GradientBoost\n",
    "# HGB HistogramGradientBoost 작년까지는 beta version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455425df-6d82-4f95-9721-a55a5bca449c",
   "metadata": {},
   "source": [
    "## 트리의 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ea7dd5-8482-4aa6-b7fe-732456792d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정형데이터에 가장 뛰어난 성능을 보이는 모델들 입니다.\n",
    "# 앙상블 모델들은 결정트리(Decision Tree)를 기반으로 만들어졌습니다.\n",
    "# 앙상블 모델들..\n",
    "# - 랜덤포레스트(Random Forest)\n",
    "# - 엑스트라 트리(Extra Trees)\n",
    "# - 그래디언트 부스팅(Gradient Boosting)\n",
    "# - 히스토그램 기반 그래디언트 부스팅(Histogram-base Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4a52ae-c37e-44d0-81b1-00838096ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 여러모델을 써야하는 이유  : 비교대상이 필요하고 최적의 모델이란것을 증명해야하기위해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa60d3ee-7db3-4ef1-92ee-20e55e9daf27",
   "metadata": {},
   "source": [
    "## 랜덤포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa152189-5116-43f3-9acb-7c79e7dc09b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 앙상블 모델 중에 가장 대표격 모델로 사용됨\n",
    "# - 안정적인 성능으로 널리 사용됨\n",
    "# - 앙상블 모델 중에 가장 먼저 시도하는 모델이라고 보면 됩니다.\n",
    "# - 훈련데이터에서 과대적합되는 것을 막아줍니다\n",
    "# - 검증데이터와 테스트데이터에서 안정적인 성능을 얻을 수 있음\n",
    "\n",
    "### 학습 개념\n",
    "# - 결정트리 하나하나를 랜덤하게 만들어서 숲을 만든다고 보시면 됩니다.\n",
    "# - 훈련데이터에서 랜덤하게 샘플을 추출하여 훈련을 완료한 후\n",
    "# - 다시 원본 훈련데이터에 반환을 합니다.\n",
    "# - 랜덤하게 추출 시 이전에 사용된 샘플을 사용할 수도 있음\n",
    "# (중복을 허용함)\n",
    "\n",
    "### 부트스트랩 샘플(Bootstrap Sample)\n",
    "# - 위에 설명한 랜덤한 샘플 추출 시 중복을 허용하여 데이터를 샘플링 하는 방식\n",
    "# - 샘플 추출 방식\n",
    "# - 1. 원본에서 랜덤 샘플 추출\n",
    "# - 2. 훈련 이후 사용이 끝나면 원본에 반환\n",
    "# - 3. 다시 원본에서 샘플 추출, 이때 중복 값 추출 될 수도 있음\n",
    "# - 위 순서를 반복하면서 샘플링을 통해 훈련하는 방식을 랜덤포레스트가 적용하고 있음\n",
    "\n",
    "### *** 랜덤포레스트는 교차검증을 허용 합니다 ***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "824d6655-5d19-46fe-9f8e-9f759e41668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dad9900-65b0-467d-9f62-9ec41350492d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4872, 3) (4872,)\n",
      "(1625, 3) (1625,)\n"
     ]
    }
   ],
   "source": [
    "### 08_wine.csv 읽어들이고 훈련 및 테스트 데이터까지 생성해 주세요 ...\n",
    "\n",
    "wine = pd.read_csv('./data/08_wine.csv')\n",
    "wine.head()\n",
    "\n",
    "data = wine[['alcohol','sugar','pH']].to_numpy()\n",
    "target = wine['class'].to_numpy()\n",
    "\n",
    "train_input, test_input, train_target, test_target = \\\n",
    "    train_test_split(data,target, random_state=42)\n",
    "\n",
    "print(train_input.shape, train_target.shape)\n",
    "print(test_input.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3a02a-424f-4519-85dd-3858607e80e8",
   "metadata": {},
   "source": [
    "## 훈련모델 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938163b6-803e-422d-ac9e-394829f014ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.26483655, 0.29620576, 0.25982141, 0.2443409 , 0.28933406,\n",
      "       0.32096195, 0.27701807, 0.26013207, 0.26331234, 0.2709012 ]), 'score_time': array([0.0149684 , 0.01491737, 0.01501107, 0.0182097 , 0.02890229,\n",
      "       0.01564622, 0.01368499, 0.01955104, 0.01113677, 0.01473427]), 'test_score': array([0.90778689, 0.87295082, 0.91581109, 0.88090349, 0.91786448,\n",
      "       0.90349076, 0.8788501 , 0.87474333, 0.87063655, 0.89117043])}\n"
     ]
    }
   ],
   "source": [
    "# 랜덤포레스트 클래스(모델) : RandomForestClassifire\n",
    "# 교차검증 : cross_validate()\n",
    "# 교차검증 후 훈련검증결과와 테스트검증결과 확인하기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "splitter = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "scores = cross_validate(RandomForestClassifier(random_state=42),train_input, train_target, cv=splitter)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a127fc3-9d0b-43a2-a749-b6775b880878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 score =  0.8914207930790724\n"
     ]
    }
   ],
   "source": [
    "print('최종 score = ', np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb2abb2-a5d4-415c-b9b8-2ad546620105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 score =  0.997844759088341 테스트 score=  0.8914208392565683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# 랜덤포레스트 객체생성 : 코어 모두 사용\n",
    "rf = RandomForestClassifier(n_jobs = -1 , random_state = 42)\n",
    "\n",
    "# 교차검증 진행\n",
    "# - return_train_score : 검증결과 반환받기\n",
    "scores = cross_validate(rf, train_input, train_target, return_train_score = True, n_jobs = -1)\n",
    "\n",
    "# 최종 훈련평가 결과 및 검증결과\n",
    "scores\n",
    "print('훈련 score = ',np.mean(scores['train_score']),'테스트 score= ' ,np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12a37af1-e471-4b87-993b-245e5cc50892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23155241, 0.49706658, 0.27138101])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train_input, train_target)\n",
    "# 특성 중요도 조회하기\n",
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96604131-53ae-472a-9a5e-7aedc194cccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981937602627258\n"
     ]
    }
   ],
   "source": [
    "### oob : 기능 사용\n",
    "# - 훈련에 참여하지 못한 잔여샘플 사용하는 기능\n",
    "# 기본은 사용안함,\n",
    "# 기본은 사용안함\n",
    "# 훈련한번더하고 검증까지\n",
    "rf = RandomForestClassifier(oob_score = True, n_jobs = -1 , random_state=42)\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab2176-6892-40bb-9656-4bf344980578",
   "metadata": {},
   "source": [
    "## 엑스트라 트리(Extra Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04cd5911-7091-4b22-a5f9-cf6e64a20349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 랜덤포레스트와 유사하게 작동\n",
    "# - 기본적으로 100개의 결정트리를 훈련함\n",
    "# - 랜덤포레스트와의 차이점\n",
    "# - 부트스트랩 샘플링을 지원하지 않음\n",
    "# - 훈련데이터 전체를 이용하여 결정트리를 생성\n",
    "# - 무작위로 트리를 분리함\n",
    "# - 사용되는 속성 : splitter = \"random\" 무작위속성\n",
    "# - 장점\n",
    "# : 과대적합을 막고, 검증데이터의 평가 값을 높일 수 있음\n",
    "# : 특성 데이터가 많지 않은 경우에는 랜덤포레스트와 큰 차이가 없음\n",
    "# - 랜덤포레스트는 불순도 등 여러가지 조건에 따라 결정 트리를 생성하기 때문에\n",
    "#   속도가 느린 반면에\n",
    "# - 엑스트라트리는 랜덤하게 결정트리를 생성하기에 속도가 다소 빠르다는 장점있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05a9f81a-6c2e-4513-9b98-ae3b91b62fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 score =  0.997844759088341 테스트 score=  0.8903937240035804\n"
     ]
    }
   ],
   "source": [
    "### 사용패키지 : 랜덤포레스트와 동일\n",
    "# 사용되는 클래스(모델) : ExtraTreesClassifier\n",
    "\n",
    "### 코어 전체사용 : train 및 test 결과값 출력 ..\n",
    "### 교차검증 결과만 train 및 test 결과 확인해 주세요\n",
    "\n",
    "train_input, test_input, train_target, test_target = \\\n",
    "    train_test_split(data,target, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
    "# 교차검증 진행\n",
    "# - return_train_score : 검증결과 반환받기\n",
    "scores = cross_validate(et, train_input, train_target, return_train_score = True, n_jobs = -1)\n",
    "\n",
    "## 최종 및 훈련평가 결과 및 검증결과\n",
    "scores\n",
    "print('훈련 score = ',np.mean(scores['train_score']),'테스트 score= ' ,np.mean(scores['test_score']))\n",
    "\n",
    "## 랜포\n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8914208392565683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e70598d2-adb4-4188-ba3c-fcc894e978f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20702369, 0.51313261, 0.2798437 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et.fit(train_input,train_target)\n",
    "et.feature_importances_\n",
    "# array([0.23155241, 0.49706658, 0.27138101]) 랜덤포레스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d47bf-3786-4131-849e-7d78afef67dc",
   "metadata": {},
   "source": [
    "## 그래디언트 부스팅(Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3846cda-8947-4ff4-881b-d4a8621a1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 깊이(max_depth)가 얖은 결정트리를 사용함\n",
    "# - 기본적으로 max_depth = 3 을 사용\n",
    "# - 결정트리는 100개 사용\n",
    "### *** 기존에 다른 훈련모델의 결과가 좋지 않을 때 사용하는 모델 ***\n",
    "# 기존 훈련모델의 오차를 많이 보완해 줍니다\n",
    "# 성능 향상을 위한 모델로 주로 사용됩니다.\n",
    "# 과대적합에 강하며, 일반화(과대/과소적합이 없는 상태)에 강합니다.\n",
    "\n",
    "# 성능향상 테스트 방법\n",
    "# - 결정트리의 갯수를 조절하면서 테스트 짆냉\n",
    "# - 학습률을 지원하기 때문에 학습률의 값을 증가시키면서 테스트 진행\n",
    "# - : 기본 학습률은 0.1\n",
    "\n",
    "\n",
    "# 단점\n",
    "# - 순서대로 트리를 추가(랜덤하지 않음)하지 않기 때문에\n",
    "# - 훈련 속도는 느림\n",
    "# - 이런 느린 속도를 개선한 모델이\n",
    "#  '히스토그램 기반 그래디언트 부스팅' 모델임\n",
    "\n",
    "# 어느때 어떻게 써야될지 생각하는게 어렵다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a463aa0-8910-4b7e-ad00-b9a1cbf77c0c",
   "metadata": {},
   "source": [
    "## 그래디언트 부스팅 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a04ee6cf-3488-40ff-9b78-aa1a7e664e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 score =  0.8894704231708938 테스트 score=  0.8715107671247301\n"
     ]
    }
   ],
   "source": [
    "### 사용하는 클래스(모델) : GradientBoostingClassifier\n",
    "# 객체 생성시 아무것도 안주고 seed값만 줍니다.\n",
    "# 교차검증시에는 train, test 결과값 출력 합니다.\n",
    "train_input, test_input, train_target, test_target = \\\n",
    "    train_test_split(data,target, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "scores = cross_validate(gb, train_input, train_target, return_train_score = True, n_jobs = -1)\n",
    "\n",
    "print('훈련 score = ',np.mean(scores['train_score']),'테스트 score= ' ,np.mean(scores['test_score']))\n",
    "\n",
    "# (해석 ) 과대적합이 줄었다 => 모델이 일반화 되었다, 성능은 감소하였다 0.1이상 격차가 나면 선택하면 안된다\n",
    "# 우선순위 : 일반화된거 선택해야함\n",
    "# 성능향상시킬 필요는 있음\n",
    "\n",
    "## 랜포\n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8914208392565683\n",
    "## 엑스트라트리 \n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8903937240035804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03b699b5-1968-4667-bf83-da73e5caeaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20702369 0.51313261 0.2798437 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8578461538461538"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(train_input, train_target)\n",
    "print(et.feature_importances_)\n",
    "gb.score(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774073b7-26d0-4068-b6de-f911403e6252",
   "metadata": {},
   "source": [
    "## 학습률 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4f5b366-6530-4870-ad09-ff9494b61f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   학습률이 커지면 트리 보정을 강하게 하기 때문에,\n",
    "#   복잡한 모델을 만들어서 일반화 성능을 떨어뜨리게 된다.\n",
    "# 학습률 : learning_rate = 0.1 기본값...\n",
    "# 값이 낮을수록 과대적합, 과소적합을 줄여줄수있다\n",
    "# 값을 너무 올리면 복잡도가 엄청나게 강해진다 => 과대적합가능성이 오른다 일반화 떨어진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71c5eef8-c255-4bf4-858f-df20bd4b50ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 score =  0.8894704231708938 테스트 score=  0.8715107671247301\n"
     ]
    }
   ],
   "source": [
    "# 훈련 반복횟수 n_estimator\n",
    "train_input, test_input, train_target, test_target = \\\n",
    "    train_test_split(data,target, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gd = GradientBoostingClassifier(n_estimators = 100,\n",
    "                                learning_rate = 0.1,\n",
    "                                random_state = 42)\n",
    "scores = cross_validate(gd, train_input, train_target, return_train_score = True, n_jobs = -1)\n",
    "\n",
    "print('훈련 score = ',np.mean(scores['train_score']),'테스트 score= ' ,np.mean(scores['test_score']))\n",
    "\n",
    "# 학습률은 안건드리는게 좋다 올리면 과대적합이 발생할 가능성이 늘어난다\n",
    "# 과소적합일때는 올려서 테스트할 필요는 있다\n",
    "\n",
    "\n",
    "## 랜포\n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8914208392565683\n",
    "## 엑스트라트리 \n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8903937240035804"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4ae57-6c39-4909-b3ba-816cb389fb39",
   "metadata": {},
   "source": [
    "## 히스토그램 기반 그래디언트 부스팅\n",
    "##### -Histogram-base Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80eee7e9-1989-4907-878d-9911207adfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 score =  0.9380129799494501 테스트 score=  0.8805410414363187\n"
     ]
    }
   ],
   "source": [
    "## 사용하는 클래스(모델) : HistGradientBoostingClassifier()\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(hgb, train_input, train_target, return_train_score = True, n_jobs = -1)\n",
    "print('훈련 score = ',np.mean(scores['train_score']),'테스트 score= ' ,np.mean(scores['test_score']))\n",
    "\n",
    "## 랜포\n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8914208392565683\n",
    "## 엑스트라트리 \n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8903937240035804\n",
    "## 그래디언트\n",
    "# 훈련 score =  0.8894704231708938 테스트 score=  0.8715107671247301\n",
    "## HGB\n",
    "# 훈련 score =  0.9380129799494501 테스트 score=  0.8805410414363187\n",
    "\n",
    "## (해석) 0.05정도의 차이니까 HGB선택한다\n",
    "# 좋은모델정도?로 평가한다 굉장히 주관적이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5a64c8a-b107-4ddb-94b7-cc0fc3f0e554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8584615384615385"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgb.fit(train_input, train_target)\n",
    "hgb.score(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b3dd4-f07c-4f85-a18e-2d9ca7068dee",
   "metadata": {},
   "source": [
    "## 사이킷런 이외 다른 패키지에서 지원하는\n",
    "## 히스토그램 기반 그래디언트 부스팅 기능 모델들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c7638-7cc0-45d1-8885-9b14cc3dddaa",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0400c2e2-f8fb-4c4d-9159-79115d87b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다 사용하시는 분들 : conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dee3152-ddf9-4aee-a090-df07e150133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 score =  0.9614122399872658 테스트 score=  0.8834151529510873\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(tree_method=\"hist\", random_state=42)\n",
    "\n",
    "scores = cross_validate(xgb, train_input, train_target, return_train_score = True, n_jobs = -1)\n",
    "print('훈련 score = ',np.mean(scores['train_score']),'테스트 score= ' ,np.mean(scores['test_score']))\n",
    "## 랜포\n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8914208392565683\n",
    "## 엑스트라트리 \n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8903937240035804\n",
    "## 그래디언트\n",
    "# 훈련 score =  0.8894704231708938 테스트 score=  0.8715107671247301\n",
    "## HGB\n",
    "# 훈련 score =  0.9380129799494501 테스트 score=  0.8805410414363187\n",
    "## xgb\n",
    "# 훈련 score =  0.9614122399872658 테스트 score=  0.8834151529510873"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653856e1-69b6-4509-8cf9-4448acb76b98",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e96b291a-d777-44de-ae5e-d41b73825249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 마이크로소프트에서 만든 히스토그램 기반 그레디언트 부스트 패키지\n",
    "# - 훈련 속도가 매우 빠름\n",
    "# - 최신 기술을 많이 적용하고 있어서, 인기가 올라가고 있음\n",
    "# - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "770529a4-9c77-4ae3-8728-132f6d7f0097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 score =  0.9413484712095832 테스트 score=  0.8846461327857632\n"
     ]
    }
   ],
   "source": [
    "# 아나콘다 사용하시는 분들 : conda install -c conda-forge lightgbm\n",
    "# 파이썬 기반 사용하시는분들 pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(lgbm, train_input, train_target, return_train_score = True, n_jobs = -1)\n",
    "print('훈련 score = ',np.mean(scores['train_score']),'테스트 score= ' ,np.mean(scores['test_score']))\n",
    "\n",
    "## 랜포\n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8914208392565683\n",
    "## 엑스트라트리 \n",
    "# 훈련 score =  0.997844759088341 테스트 score=  0.8903937240035804\n",
    "## 그래디언트\n",
    "# 훈련 score =  0.8894704231708938 테스트 score=  0.8715107671247301\n",
    "\n",
    "## HGB\n",
    "# 훈련 score =  0.9380129799494501 테스트 score=  0.8805410414363187\n",
    "## xgb\n",
    "# 훈련 score =  0.9614122399872658 테스트 score=  0.8834151529510873\n",
    "# lightgbm\n",
    "# 훈련 score =  0.9413484712095832 테스트 score=  0.8846461327857632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b03b265e-020a-4273-b679-e9cb519eb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내일은 비정형 데이터 머신러닝 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdcbd8c-5e99-4213-89f5-08563609869c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
